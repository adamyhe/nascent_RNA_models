{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f0d0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# point to durga GPU\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"MIG-f80e9374-504a-571b-bac0-6fb00750db4c\"\n",
    "# point to nandi GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344189f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import gzip\n",
    "from tqdm import tqdm\n",
    "import pyBigWig\n",
    "from pyfaidx import Fasta\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "\n",
    "model_cell_type = \"K562\"\n",
    "\n",
    "timestamps = [\"2023-05-29_15-51-40\",\n",
    "              \"2023-05-29_15-58-41\",\n",
    "              \"2023-05-29_15-59-09\",\n",
    "              \"2023-05-30_01-40-06\",\n",
    "              \"2023-05-29_23-21-23\",\n",
    "              \"2023-05-29_23-23-45\",\n",
    "              \"2023-05-29_23-24-11\"]\n",
    "\n",
    "in_window = 2114\n",
    "out_window = 1000\n",
    "\n",
    "\n",
    "# filepaths\n",
    "\n",
    "proj_dir = \"/mnt/lab_data2/kcochran/procapnet/\"\n",
    "genome_path = proj_dir + \"genomes/hg38.withrDNA.fasta\"\n",
    "chrom_sizes = proj_dir + \"genomes/hg38.withrDNA.chrom.sizes\"\n",
    "gtf_filepath = proj_dir + \"annotations/gencode.v41.annotation.gtf.gz\"\n",
    "\n",
    "all_procap_peak_path = proj_dir + \"data/procap/processed/\" + model_cell_type + \"/peaks.bed.gz\"\n",
    "plus_bw_path = proj_dir + \"data/procap/processed/\" + model_cell_type + \"/5prime.pos.bigWig\"\n",
    "minus_bw_path = proj_dir + \"data/procap/processed/\" + model_cell_type + \"/5prime.neg.bigWig\"\n",
    "\n",
    "model_save_paths = [proj_dir + \"models/procap/\" + model_cell_type + \"/strand_merged_umap/\" + timestamp + \".model\" for timestamp in timestamps]\n",
    "\n",
    "\n",
    "genes_list_path = \"genes_to_screen.csv\"  # from Shreya\n",
    "\n",
    "candidate_promoter_regions_bed = \"TSS_windows.merge.bed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc1e7d4",
   "metadata": {},
   "source": [
    "## Pre-processing Regions To Apply Model To"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2647f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load info for genes (and transcripts, for TSSs) from GENCODE GTF\n",
    "\n",
    "def load_gtf(gtf_filepath, region_types_to_load = [\"gene\", \"transcript\"]):\n",
    "    regions = defaultdict(lambda : [])\n",
    "    \n",
    "    if gtf_filepath.endswith(\".gz\"):\n",
    "        f = gzip.open(gtf_filepath)\n",
    "    else:\n",
    "        f = open(gtf_filepath)\n",
    "        \n",
    "    for line in f:\n",
    "        if gtf_filepath.endswith(\".gz\"):\n",
    "            line = line.decode()\n",
    "        \n",
    "        if line.startswith(\"#\"):\n",
    "            continue  # skip header\n",
    "        \n",
    "        chrom, _, label, start, end, _, strand = line.split()[:7]\n",
    "\n",
    "        if label in region_types_to_load:\n",
    "            if label == \"gene\":\n",
    "                gene_name = line.split()[13][1:-2]\n",
    "            else:\n",
    "                gene_name = line.split()[15][1:-2]  # second indexing is to remove \"...\";\n",
    "\n",
    "            regions[label].append((chrom, start, end, strand, gene_name))\n",
    "            \n",
    "    f.close()\n",
    "    return regions\n",
    "\n",
    "\n",
    "gtf_regions = load_gtf(gtf_filepath)\n",
    "assert len(gtf_regions) > 0, len(gtf_regions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1c06b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Shreya's gene list\n",
    "\n",
    "def load_genes_to_screen(csv_path):\n",
    "    df = pd.read_csv(csv_path, sep=\",\")\n",
    "    return list(df[\"gene_name\"])\n",
    "    \n",
    "gene_names = load_genes_to_screen(genes_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488db96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MT-RNR1', 'PJA2', 'MYO15B', 'MRFAP1', 'SCAMP4', 'PLXND1', 'IPO7', 'CNOT1', 'DAZAP2', 'RN7SL1', 'CROCCP2', 'ATP6AP1', 'PPIA', 'ARAP1', 'TLN1', 'NEAT1', 'MTATP6P1', 'PRKDC', 'MTMR9LP', 'ATP5F1B', 'LENG8', 'THUMPD3-AS1', 'RCC1L', 'SRRM2', 'HNRNPF', 'MALAT1', 'LSM14A', 'CAPZA2', 'MTCO1P12', 'NCKAP1L', 'RNPS1', 'REPIN1', 'CAPNS1', 'ZNF407-AS1', 'CLTC', 'TMX2', 'GNA13', 'RBM12', 'PTMS', 'PILRA', 'ACACA', 'RAB31', 'MYO5A', 'DCTN1', 'CCNL2', 'ATXN7L3B', 'ZBTB7A', 'RANBP2', 'ARPC5', 'DENND4B', 'RHOA', 'RBM14', 'VPS52', 'G3BP1', 'SEPTIN2', 'SNX3', 'DCLRE1A', 'EP400', 'WBP2', 'EIF3A', 'TAF9', 'PFKL', 'SF1', 'JUND', 'NOL7', 'TMEM259', 'FNIP1', 'STK40', 'RAB11B', 'SET', 'ATP6V1C1', 'AGRN', 'HNRNPU', 'SF3B1', 'ARF6', 'HNRNPH1', 'HCLS1', 'CICP14', 'DOCK2', 'ZNF8', 'ILF3', 'ACADVL', 'ZNHIT3', 'TADA2A']\n"
     ]
    }
   ],
   "source": [
    "print(gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7af0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull genes of interest from the loaded GTF data\n",
    "# for every gene, get all transcripts and their start sites\n",
    "# then for every TSS, draw a window of sequence you will make predictions for\n",
    "\n",
    "\n",
    "def filter_for_target_genes(gtf_regions, gene_names):\n",
    "    target_regions = []\n",
    "    for region in gtf_regions:\n",
    "        gene_name = region[-1]\n",
    "        if not (gene_name in gene_names):\n",
    "            continue\n",
    "        target_regions.append(region)\n",
    "        \n",
    "    return target_regions\n",
    "\n",
    "\n",
    "def assemble_info_for_genes(gtf_regions, gene_names):\n",
    "    # try loading in all genes by gene name\n",
    "    target_genes_info = filter_for_target_genes(gtf_regions[\"gene\"], gene_names)\n",
    "    \n",
    "    # check we find all the genes we expect (and nothing extra)\n",
    "    assert set([info[-1] for info in target_genes_info]) == set(gene_names)\n",
    "    \n",
    "    # then load in all transcripts for those genes in the same way\n",
    "    transcripts_info = filter_for_target_genes(gtf_regions[\"transcript\"], gene_names)\n",
    "    \n",
    "    # simplify GTF-pulled info into just the gene name and the coordinates + strand\n",
    "    genes_to_transcript_locations = defaultdict(lambda : [])\n",
    "    for transcript in transcripts_info:\n",
    "        gene_for_transcript = transcript[-1]\n",
    "        transcript_location = transcript[:-1]\n",
    "        \n",
    "        genes_to_transcript_locations[gene_for_transcript].append(transcript_location)\n",
    "    \n",
    "    # for each transcript, process coordinates into just the 1bp TSS\n",
    "    TSSs_per_gene = defaultdict(lambda : set())\n",
    "    for gene_name, transcripts in genes_to_transcript_locations.items():\n",
    "        for (chrom, start, end, strand) in transcripts:\n",
    "            if strand == \"+\":\n",
    "                TSS_annot = int(start)\n",
    "            else:\n",
    "                TSS_annot = int(end)\n",
    "            \n",
    "            # the -1 is to convert 1-indexed GTF coords into 0-indexed BED coords\n",
    "            TSSs_per_gene[gene_name].add((chrom, TSS_annot - 1, TSS_annot, strand))\n",
    "    \n",
    "    # around each TSS, how large of a window to consider\n",
    "    extend_by = 2000\n",
    "    \n",
    "    # extend windows +/- 2kb around each TSS (wide \"candidate promoter region\")\n",
    "    TSS_windows_per_gene = defaultdict(lambda : [])\n",
    "    for gene_name, TSSs in TSSs_per_gene.items():\n",
    "        for chrom, start, end, strand in TSSs:\n",
    "            # because we already convert into BED coords above, un-adjust by 1 here\n",
    "            start = max(0, start - extend_by + 1)\n",
    "            end = end + extend_by\n",
    "            assert end - start == extend_by * 2 or start == 0, end - start\n",
    "            \n",
    "            TSS_windows_per_gene[gene_name].append((chrom, start, end, strand))\n",
    "    \n",
    "    return TSS_windows_per_gene\n",
    "    \n",
    "    \n",
    "TSS_windows_per_gene = assemble_info_for_genes(gtf_regions, gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4491125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the windows we will use into a BED file\n",
    "# merge overlaps to avoid redundancy (we will tile predictions across regions anyways)\n",
    "\n",
    "def write_regions_to_bed_file(regions, filepath):\n",
    "    regions = sorted(regions, key = lambda region : (region[0], int(region[1])))\n",
    "    if filepath.endswith(\".gz\"):\n",
    "        with gzip.open(filepath, \"w\") as f:\n",
    "            for region_info in regions:\n",
    "                line = \"\\t\".join([str(thing) for thing in region_info]) + \"\\n\"\n",
    "                f.write(line.encode())\n",
    "    else:\n",
    "        with open(filepath, \"w\") as f:\n",
    "            for region_info in regions:\n",
    "                line = \"\\t\".join([str(thing) for thing in region_info]) + \"\\n\"\n",
    "                f.write(line)\n",
    "                \n",
    "                \n",
    "def run_bedtools_merge(filepath_i, dest_filepath, other_args=[]):\n",
    "    cmd = [\"bedtools\", \"merge\"]\n",
    "    cmd += [\"-i\", filepath_i]\n",
    "    for arg in other_args:\n",
    "        cmd += [arg]\n",
    "        \n",
    "    with open(dest_filepath, \"w\") as outf:\n",
    "        subprocess.call(cmd, stdout=outf)\n",
    "\n",
    "\n",
    "def write_TSS_windows_to_bed(TSS_windows):\n",
    "    flattened_list = []\n",
    "    for gene_name, windows in TSS_windows.items():\n",
    "        # adding gene name to info to write to file\n",
    "        # also need to make strand info be in the 6th column for bedtools \n",
    "        flattened_list.extend([list(w[:-1]) + [gene_name, \".\", w[-1]] for w in windows])\n",
    "        \n",
    "    write_regions_to_bed_file(flattened_list, \"TSS_windows.premerge.bed\")\n",
    "    run_bedtools_merge(\"TSS_windows.premerge.bed\", candidate_promoter_regions_bed,\n",
    "                       other_args=[\"-s\", \"-c\", \"4,5,6\", \"-o\", \"distinct,distinct,distinct\"])\n",
    "    \n",
    "    \n",
    "write_TSS_windows_to_bed(TSS_windows_per_gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d5331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1\t629074\t635696\tMTATP6P1,MTCO1P12\t.\t+\r\n",
      "chr1\t1018120\t1022123\tAGRN\t.\t+\r\n",
      "chr1\t1032106\t1036867\tAGRN\t.\t+\r\n",
      "chr1\t1043399\t1053986\tAGRN\t.\t+\r\n",
      "chr1\t1386713\t1394716\tCCNL2\t.\t-\r\n",
      "chr1\t1396287\t1401335\tCCNL2\t.\t-\r\n",
      "chr1\t16624386\t16633109\tCROCCP2\t.\t-\r\n",
      "chr1\t16642672\t16646686\tCROCCP2\t.\t-\r\n",
      "chr1\t16655232\t16659232\tCROCCP2\t.\t-\r\n",
      "chr1\t32238247\t32243710\tMTMR9LP\t.\t-\r\n"
     ]
    }
   ],
   "source": [
    "! head $candidate_promoter_regions_bed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff65709",
   "metadata": {},
   "source": [
    "## Applying Model To Candidate Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4d388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the sequences at the regions we just defined\n",
    "\n",
    "# see bpnetlite repo for better documentation on all this loading code\n",
    "# https://github.com/jmschrei/bpnet-lite\n",
    "\n",
    "# same functionality as Kelly's usual code, but also loads chrM\n",
    "# also loads in the starts and stops according to the bed file (+ widths)\n",
    "# (not a standardized in-out window size for all examples)\n",
    "\n",
    "\n",
    "def one_hot_encode(sequence, alphabet=['A','C','G','T'], dtype='int8', \n",
    "    desc=None, verbose=False, **kwargs):\n",
    "    # Converts a string or list of characters into a one-hot encoding.\n",
    "    # from bpnet-lite / Jacob\n",
    "    \n",
    "    # these characters will be encoded as all-zeros\n",
    "    ambiguous_nucs = [\"Y\", \"R\", \"W\", \"S\", \"K\", \"M\", \"D\", \"V\", \"H\", \"B\", \"X\", \"N\"]\n",
    "\n",
    "    d = verbose is False\n",
    "\n",
    "    sequence = sequence.upper()\n",
    "    if isinstance(sequence, str):\n",
    "        sequence = list(sequence)\n",
    "\n",
    "    alphabet = alphabet or np.unique(sequence)\n",
    "    alphabet_lookup = {char: i for i, char in enumerate(alphabet)}\n",
    "\n",
    "    ohe = np.zeros((len(sequence), len(alphabet)), dtype=dtype)\n",
    "    for i, char in tqdm(enumerate(sequence), disable=d, desc=desc, **kwargs):\n",
    "        if char in alphabet:\n",
    "            idx = alphabet_lookup[char]\n",
    "            ohe[i, idx] = 1\n",
    "        else:\n",
    "            assert char in ambiguous_nucs, char\n",
    "\n",
    "    return ohe\n",
    "\n",
    "\n",
    "def read_fasta_fast(filename, chrom_sizes=None, include_chroms=None, verbose=True):\n",
    "    # Read in a FASTA file and output a dictionary of sequences\n",
    "    # from bpnet-lite / Jacob\n",
    "    \n",
    "    if include_chroms is None:\n",
    "        if chrom_sizes is None:\n",
    "            print(\"Assuming human chromosomes in read_fasta_fast.\")\n",
    "            include_chroms = [\"chr\" + str(i + 1) for i in range(22)]\n",
    "            include_chroms.extend([\"chrX\", \"chrY\", \"chrM\"])\n",
    "        else:\n",
    "            include_chroms = load_chrom_names(chrom_sizes)\n",
    "\n",
    "    chroms = {}\n",
    "    print(\"Loading genome sequence from \" + filename)\n",
    "    fasta_index = Fasta(filename)\n",
    "    for chrom in tqdm(include_chroms, disable=not verbose, desc=\"Reading FASTA\"):\n",
    "        chroms[chrom] = fasta_index[chrom][:].seq.upper()\n",
    "    return chroms\n",
    "\n",
    "\n",
    "def load_sequences(genome_path, chrom_sizes, peak_path,\n",
    "                  verbose=False):\n",
    "\n",
    "    seqs = []\n",
    "    in_width = in_window // 2\n",
    "\n",
    "    assert os.path.exists(genome_path), genome_path\n",
    "    sequences = read_fasta_fast(genome_path, verbose=verbose)\n",
    "\n",
    "    names = ['chrom', 'start', 'end']\n",
    "    assert os.path.exists(peak_path), peak_path\n",
    "    peaks = pd.read_csv(peak_path, sep=\"\\t\", usecols=(0, 1, 2), \n",
    "        header=None, index_col=False, names=names)\n",
    "\n",
    "    desc = \"Loading Peaks\"\n",
    "    d = not verbose\n",
    "    for _, (chrom, og_start, og_end) in tqdm(peaks.iterrows(), disable=d, desc=desc):\n",
    "        # Append sequence to growing sequence list\n",
    "        \n",
    "        # get sequence from fasta for this chromosome\n",
    "        chrom_sequence = sequences[chrom]\n",
    "        \n",
    "        # determine beginning and end of region (extend out by model input width)\n",
    "        s = max(0, og_start - in_width)\n",
    "        e = og_end + in_width\n",
    "        assert s >= 0, s\n",
    "\n",
    "        if isinstance(chrom_sequence, str):\n",
    "            seq = one_hot_encode(chrom_sequence[s:e]).T\n",
    "        else:\n",
    "            seq = chrom_sequence[s:e].T\n",
    "\n",
    "        assert seq.shape == (4, e - s), (seq.shape, s, e)\n",
    "        assert set(seq.flatten()) == set([0,1]), set(seq.flatten())\n",
    "        # the following asserts allow for [0,0,0,0] as a valid base encoding\n",
    "        assert set(seq.sum(axis=0)).issubset(set([0, 1])), set(seq.sum(axis=0))\n",
    "        assert seq.sum() <= e - s, seq\n",
    "        seqs.append(seq)\n",
    "        \n",
    "    to_print = \"\\nPeak filepath: \" + peak_path\n",
    "    to_print += \"\\nNum. examples loaded: \" + str(len(seqs))\n",
    "    print(to_print)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return seqs\n",
    "\n",
    "onehot_seqs = load_sequences(genome_path, chrom_sizes, candidate_promoter_regions_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e510ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(plus_bw_path, minus_bw_path, peak_path,\n",
    "                       verbose=False):\n",
    "\n",
    "    signals = []\n",
    "    out_width = out_window // 2\n",
    "\n",
    "    names = ['chrom', 'start', 'end']\n",
    "    assert os.path.exists(peak_path), peak_path\n",
    "    peaks = pd.read_csv(peak_path, sep=\"\\t\", usecols=(0, 1, 2), \n",
    "        header=None, index_col=False, names=names)\n",
    "\n",
    "    assert os.path.exists(plus_bw_path), plus_bw_path\n",
    "    assert os.path.exists(minus_bw_path), minus_bw_path\n",
    "    plus_bw = pyBigWig.open(plus_bw_path, \"r\")\n",
    "    minus_bw = pyBigWig.open(minus_bw_path, \"r\")\n",
    "\n",
    "    desc = \"Loading Peaks\"\n",
    "    d = not verbose\n",
    "    for _, (chrom, og_start, og_end) in tqdm(peaks.iterrows(), disable=d, desc=desc):\n",
    "        start = max(0, og_start - out_width)\n",
    "        end = og_end + out_width\n",
    "        assert start >= 0, start\n",
    "\n",
    "        # Load plus strand signal\n",
    "        plus_sig = plus_bw.values(chrom, start, end, numpy=True)\n",
    "        plus_sig = np.nan_to_num(plus_sig)\n",
    "\n",
    "        # Load minus strand signal\n",
    "        minus_sig = minus_bw.values(chrom, start, end, numpy=True)\n",
    "        minus_sig = np.nan_to_num(minus_sig)\n",
    "\n",
    "        # Append signal to growing signal list\n",
    "        assert len(plus_sig) == end - start, (len(plus_sig), start, end)\n",
    "        assert len(minus_sig) == end - start, (len(minus_sig), start, end)\n",
    "        signals.append(np.array([plus_sig, minus_sig]))\n",
    "    \n",
    "    to_print += \"\\nPeak filepath: \" + peak_path\n",
    "    to_print += \"\\nNum. examples loaded: \" + str(len(signals))\n",
    "    print(to_print)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    return signals\n",
    "\n",
    "\n",
    "true_profs = load_data(plus_bw_path, minus_bw_path, candidate_promoter_regions_bed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c117d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# might need to deal with the chrM gene separately because it had to be loaded weirdly\n",
    "# (too close to end of chromosome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df2995e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d80f4d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../2_train_models\")\n",
    "from BPNet_strand_merged_umap import Model\n",
    "\n",
    "def load_model(model_save_path):\n",
    "    model = torch.load(model_save_path)\n",
    "    model = model.eval()\n",
    "    return model\n",
    "\n",
    "models = [load_model(model_save_path) for model_save_path in model_save_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbbd81",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80eddbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 228/228 [2:28:07<00:00, 38.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# for each candidate promoter region:\n",
    "# chunk sequence into all possible contiguous 2114bp tiles (that's the model input size)\n",
    "# make a prediction for each chunk\n",
    "# put predictions into giant numpy array of nans, tiled like sequence was\n",
    "# take nanmean (overlapping predictions averaged appropriately)\n",
    "\n",
    "def model_predict_with_rc(model, onehot_seq):\n",
    "    model = model.cuda()\n",
    "    with torch.no_grad():\n",
    "        onehot_seq = onehot_seq[None, ...].cuda()\n",
    "        pred_profiles, pred_logcounts = model.predict(onehot_seq)\n",
    "        rc_pred_profiles, rc_pred_logcounts = model.predict(torch.flip(onehot_seq, [-1, -2]))\n",
    "    \n",
    "    model = model.cpu()\n",
    "    \n",
    "    # reverse-complement (strand-flip) BOTH of the predictions\n",
    "    rc_pred_profiles = rc_pred_profiles[:, ::-1, ::-1]\n",
    "    rc_pred_logcounts = rc_pred_logcounts[:, ::-1]\n",
    "    \n",
    "    # take the average prediction across the fwd and RC sequences\n",
    "    merged_pred_profiles = np.log(np.array([np.exp(pred_profiles), np.exp(rc_pred_profiles)]).mean(axis=0))\n",
    "    merged_pred_logcounts = np.array([pred_logcounts, rc_pred_logcounts]).mean(axis=0)\n",
    "    \n",
    "    return merged_pred_profiles, merged_pred_logcounts\n",
    "\n",
    "\n",
    "def predict_one_seq(onehot_seq, models, skip = 50):\n",
    "    onehot_seq = torch.Tensor(onehot_seq).float()\n",
    "    assert len(onehot_seq.shape) == 2 and onehot_seq.shape[0] == 4, onehot_seq.shape\n",
    "    \n",
    "    num_seq_tiles = int(np.ceil((onehot_seq.shape[-1] - in_window) / skip + 1))\n",
    "    \n",
    "    preds_all = np.empty((num_seq_tiles, 2, onehot_seq.shape[-1] - (in_window - out_window)))\n",
    "    preds_all[:] = np.nan\n",
    "    \n",
    "    tiles_to_do = list(skip * np.arange(0, num_seq_tiles - 1))\n",
    "    # if not a nice even number of tiles to do vs. skips, tack on last window\n",
    "    if tiles_to_do[-1] != onehot_seq.shape[1] - in_window:\n",
    "        tiles_to_do.append(onehot_seq.shape[1] - in_window)\n",
    "\n",
    "    assert len(tiles_to_do) == num_seq_tiles, (len(tiles_to_do), num_seq_tiles)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for tile_i, tile_i_skip in enumerate(tiles_to_do):\n",
    "            assert tile_i_skip + in_window <= onehot_seq.shape[1], (tile_i_skip + in_window, onehot_seq.shape[1])\n",
    "            seq_tile = onehot_seq[:, tile_i_skip : tile_i_skip + in_window]\n",
    "            \n",
    "            pred_profs_across_models = []\n",
    "            pred_logcounts_across_models = []\n",
    "            for model in models:\n",
    "                pred_prof, pred_logcounts = model_predict_with_rc(model, seq_tile)\n",
    "                pred_profs_across_models.append(pred_prof)\n",
    "                pred_logcounts_across_models.append(pred_logcounts)\n",
    "            \n",
    "            pred_prof_avg_across_models = np.mean(np.exp(np.array(pred_profs_across_models)), axis=0)\n",
    "            pred_counts_avg_across_models = np.exp(np.mean(np.array(pred_logcounts_across_models), axis=0))\n",
    "            \n",
    "            pred_prof_scaled = (pred_prof_avg_across_models * pred_counts_avg_across_models).squeeze()\n",
    "\n",
    "            assert preds_all[tile_i, :, tile_i_skip : pred_prof_scaled.shape[-1] + tile_i_skip].shape == pred_prof_scaled.shape, (preds_all[tile_i, tile_i_skip : pred_prof_scaled.shape[-1] + tile_i_skip].shape, pred_prof_scaled.shape)\n",
    "            preds_all[tile_i, :, tile_i_skip : pred_prof_scaled.shape[-1] + tile_i_skip] = pred_prof_scaled\n",
    "    \n",
    "    preds_final = np.nanmean(preds_all, axis=0)\n",
    "    return preds_final\n",
    "\n",
    "\n",
    "def predict_all_seqs_all_models(onehot_seqs, models):\n",
    "    return [predict_one_seq(seq, models) for seq in tqdm(onehot_seqs)]\n",
    "\n",
    "\n",
    "all_preds = predict_all_seqs_all_models(onehot_seqs, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1edda596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# old\n",
    "def predict_one_seq_old(onehot_seq, model, skip = 50):\n",
    "    onehot_seq = torch.Tensor(onehot_seq).float()\n",
    "    assert len(onehot_seq.shape) == 2 and onehot_seq.shape[0] == 4, onehot_seq.shape\n",
    "    \n",
    "    #num_seq_tiles = onehot_seq.shape[1] - in_window + 1\n",
    "    num_seq_tiles = int(np.ceil((onehot_seq.shape[1] - in_window) / skip + 1))\n",
    "    \n",
    "    preds_all = np.empty((num_seq_tiles, 2, out_window + num_seq_tiles - 1))\n",
    "    preds_all[:] = np.nan\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for tile_i in range(num_seq_tiles):\n",
    "            assert tile_i + in_window <= onehot_seq.shape[1], (tile_i + in_window, onehot_seq.shape[1])\n",
    "            seq_tile = onehot_seq[:, tile_i : tile_i + in_window]\n",
    "            \n",
    "            pred_prof, pred_logcounts = model(seq_tile[None, ...].cuda())\n",
    "            \n",
    "            pred_prof_scaled = (np.exp(pred_prof.cpu().numpy()) * np.exp(pred_logcounts.cpu().numpy())).squeeze()\n",
    "\n",
    "            assert preds_all[tile_i, :, tile_i : pred_prof_scaled.shape[-1] + tile_i].shape == pred_prof_scaled.shape, (preds_all[tile_i, tile_i : pred_prof_scaled.shape[-1] + tile_i].shape, pred_prof_scaled.shape)\n",
    "            preds_all[tile_i, :, tile_i : pred_prof_scaled.shape[-1] + tile_i] = pred_prof_scaled\n",
    "    \n",
    "    preds_final = np.nanmean(preds_all, axis=0)\n",
    "    return preds_final\n",
    "\n",
    "\n",
    "def predict_all_seqs(onehot_seqs, model):\n",
    "    return [predict_one_seq_old(seq, model.cuda()) for seq in onehot_seqs]\n",
    "\n",
    "\n",
    "all_preds_old = predict_all_seqs(onehot_seqs[:100], models[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5a97342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model predictions as a dump of lots of little numpy files\n",
    "# (not ideal)\n",
    "\n",
    "tmp_save_dir = \"preds_npys_v2/\"\n",
    "\n",
    "os.makedirs(tmp_save_dir, exist_ok=True)\n",
    "\n",
    "for pred_i, pred in enumerate(all_preds):\n",
    "    np.save(tmp_save_dir + str(pred_i) + \".npy\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "80648c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_obs_corr = np.corrcoef(np.log(all_pred_counts + 1), np.log(all_true_profs + 1))[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c76e871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 350x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.ticker import LogLocator\n",
    "\n",
    "plt.figure(figsize=(3.5,3))\n",
    "plt.scatter(all_pred_counts, all_true_profs, s=2)\n",
    "plt.xlabel(\"Predicted PRO-cap Signal\", fontsize=12)\n",
    "plt.ylabel(\"Observed PRO-cap Signal\", fontsize=12)\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.xlim(0.3, 10**5.3)\n",
    "plt.ylim(0.3, 10**5.3)\n",
    "plt.gca().xaxis.set_minor_locator(LogLocator(numticks=999, subs=\"auto\"))\n",
    "plt.gca().spines[[\"top\", \"right\"]].set_visible(False)\n",
    "\n",
    "plt.text(0.7, 10**4.5, r'pearson $r$ = ' + \"%0.2f\" % (pred_obs_corr))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ffe7ab25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predicted profiles to bigwigs.\n",
      "Peaks: TSS_windows.merge.bed\n",
      "Save prefix: tracks_v2/TSS_windows.preds\n",
      "Chrom sizes file: /mnt/lab_data2/kcochran/procapnet/genomes/hg38.withrDNA.chrom.sizes\n"
     ]
    }
   ],
   "source": [
    "# save the model predictions as a genome-wide bigwig\n",
    "# (overlapping predictions will be averaged)\n",
    "\n",
    "# edited from Kelly's usual code to allow for ragged sequence length input\n",
    "\n",
    "\n",
    "def load_chrom_names(chrom_sizes, filter_out = [\"_\", \"Un\", \"EBV\"], filter_in = [\"chr\"]):\n",
    "    with open(chrom_sizes) as f:\n",
    "        lines = f.readlines()\n",
    "    lines = [line.strip().split() for line in lines]\n",
    "    chroms = [line[0] for line in lines]\n",
    "    \n",
    "    if filter_out and len(filter_out) > 0:\n",
    "        chroms = [c for c in chroms if all([filt not in c for filt in filter_out])]\n",
    "    if filter_in and len(filter_in) > 0:\n",
    "        chroms = [c for c in chroms if all([filt in c for filt in filter_in])]\n",
    "    return chroms\n",
    "\n",
    "\n",
    "def load_chrom_sizes(chrom_sizes_filepath):\n",
    "    with open(chrom_sizes_filepath) as f:\n",
    "        chrom_sizes_lines = [line.strip().split('\\t') for line in f]\n",
    "        chrom_sizes = [(line[0], int(line[1])) for line in chrom_sizes_lines]\n",
    "    return chrom_sizes\n",
    "\n",
    "\n",
    "def load_coords_ragged(peaks_file):\n",
    "    lines = []\n",
    "    if peaks_file.endswith(\".gz\"):\n",
    "        with gzip.open(peaks_file) as f:\n",
    "            lines = [line.decode().split()[:3] for line in f]\n",
    "    else:\n",
    "        with open(peaks_file) as f:\n",
    "            lines = [line.split()[:3] for line in f]\n",
    "            \n",
    "    coords = []\n",
    "    for line in lines:\n",
    "        chrom, start, end = line[0], int(line[1]), int(line[2])\n",
    "        peak_len = end - start\n",
    "        preds_len = peak_len + out_window\n",
    "        mid = start + (end - start) // 2\n",
    "        # last coord is calculated weird because of odd-length windows\n",
    "        coord = (chrom, mid - preds_len // 2, mid - preds_len // 2 + preds_len)\n",
    "        if coord[1] < 0:\n",
    "            coord = (chrom, 0 + (in_window - out_window) // 2, mid - preds_len // 2 + preds_len)\n",
    "        coords.append(coord)\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def make_track_values_dict(all_values, coords, chrom):\n",
    "    track_values = defaultdict(lambda : [])\n",
    "\n",
    "    for values, (coord_chrom, start, end) in zip(all_values, coords):\n",
    "        # subset to only peaks/values for the chromosome we're looking at now\n",
    "        if coord_chrom == chrom:\n",
    "            assert len(values) == end - start, (len(values), start, end, end - start)\n",
    "            \n",
    "            for position, value in enumerate(values):\n",
    "                position_offset = position + start\n",
    "                track_values[position_offset] = track_values[position_offset] + [value]\n",
    "    \n",
    "    # take the mean at each position, so that if there was ovelap, the average value is used\n",
    "    track_values = { key : sum(vals) / len(vals) for key, vals in track_values.items() }\n",
    "    return track_values\n",
    "\n",
    "\n",
    "def write_tracks_to_bigwigs(values,\n",
    "                            peaks_file,\n",
    "                            save_filepath_prefix,\n",
    "                            chrom_sizes_filepath):\n",
    "    \n",
    "    print(\"Writing predicted profiles to bigwigs.\")\n",
    "    print(\"Peaks: \" + peaks_file)\n",
    "    print(\"Save prefix: \" + save_filepath_prefix)\n",
    "    print(\"Chrom sizes file: \" + chrom_sizes_filepath)\n",
    "    \n",
    "    coords = load_coords_ragged(peaks_file)\n",
    "    assert len(coords) == len(values)\n",
    "    \n",
    "    for strand_idx, strand in enumerate([\"+\", \"-\"]):\n",
    "        # write separate bigwigs for svalues on the forward vs. reverse strands (in case of overlap)\n",
    "        if strand == \"+\":\n",
    "            bw_filename = save_filepath_prefix + \".pos.bigWig\"\n",
    "        else:\n",
    "            bw_filename = save_filepath_prefix + \".neg.bigWig\"\n",
    "        \n",
    "        values_for_strand = [vals[strand_idx] for vals in values]\n",
    "            \n",
    "        # bigwigs need to be written in order -- so we have to go chromosome by chromosome,\n",
    "        # and the chromosomes need to be numerically sorted (i.e. chr9 then chr10)\n",
    "        chrom_names = load_chrom_names(chrom_sizes_filepath)\n",
    "        chrom_order = {chrom : i for i, chrom in enumerate(chrom_names)}\n",
    "        chromosomes = sorted(list({coord[0] for coord in coords}),\n",
    "                             key = lambda chrom_str : chrom_order[chrom_str])\n",
    "            \n",
    "        bw = pyBigWig.open(bw_filename, 'w')\n",
    "        # bigwigs need headers before they can be written to\n",
    "        # the header is just the info you'd find in a chrom.sizes file\n",
    "        bw.addHeader(load_chrom_sizes(chrom_sizes_filepath))\n",
    "        \n",
    "        for chrom in chromosomes:\n",
    "            # convert arrays of scores for each peak into dict of base position : score\n",
    "            # this function will average together scores at the same position from different called peaks\n",
    "            track_values_dict = make_track_values_dict(values_for_strand, coords, chrom)\n",
    "            num_entries = len(track_values_dict)\n",
    "            \n",
    "            starts = sorted(list(track_values_dict.keys()))\n",
    "            ends = [position + 1 for position in starts]\n",
    "            values_to_write = [track_values_dict[key] for key in starts]\n",
    "            \n",
    "            assert len(values_to_write) == len(starts) and len(values_to_write) == len(ends)\n",
    "            \n",
    "            bw.addEntries([chrom for _ in range(num_entries)], \n",
    "                           starts, ends = ends, values = values_to_write)\n",
    "    \n",
    "        bw.close()\n",
    "\n",
    "\n",
    "write_tracks_to_bigwigs(all_preds, candidate_promoter_regions_bed,\n",
    "                        \"tracks_v2/TSS_windows.preds\", chrom_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208b7ac9",
   "metadata": {},
   "source": [
    "## Sequence-Interpretation Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44084ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat same process as model prediction, but this time score sequence instead\n",
    "# since this step takes forever, we will do 1 2114bp tile every 50bp (50x speedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3541e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions we need in order to run deepshap\n",
    "\n",
    "# Code borrowed, modified from Jacob Schreiber\n",
    "# https://github.com/jmschrei/bpnet-lite/blob/master/bpnetlite/attributions.py\n",
    "\n",
    "import numba\n",
    "import torch\n",
    "\n",
    "@numba.jit('void(int64, int64[:], int64[:], int32[:, :], int32[:,], int32[:, :], float32[:, :, :])')\n",
    "def _fast_shuffle(n_shuffles, chars, idxs, next_idxs, next_idxs_counts, counters, shuffled_sequences):\n",
    "    \"\"\"An internal function for fast shuffling using numba.\"\"\"\n",
    "\n",
    "    for i in range(n_shuffles):\n",
    "        for char in chars:\n",
    "            n = next_idxs_counts[char]\n",
    "\n",
    "            next_idxs_ = np.arange(n)\n",
    "            next_idxs_[:-1] = np.random.permutation(n-1)  # Keep last index same\n",
    "            next_idxs[char, :n] = next_idxs[char, :n][next_idxs_]\n",
    "\n",
    "        idx = 0\n",
    "        shuffled_sequences[i, idxs[idx], 0] = 1\n",
    "        for j in range(1, len(idxs)):\n",
    "            char = idxs[idx]\n",
    "            count = counters[i, char]\n",
    "            idx = next_idxs[char, count]\n",
    "\n",
    "            counters[i, char] += 1\n",
    "            shuffled_sequences[i, idxs[idx], j] = 1\n",
    "\n",
    "\n",
    "def dinuc_shuffle(sequence, n_shuffles=10, random_state=None):\n",
    "    if not isinstance(random_state, np.random.RandomState):\n",
    "        random_state = np.random.RandomState(random_state)\n",
    "\n",
    "    chars, idxs = torch.unique(sequence.argmax(axis=0), return_inverse=True)\n",
    "    chars, idxs = chars.numpy(), idxs.numpy()\n",
    "\n",
    "    next_idxs = np.zeros((len(chars), sequence.shape[1]), dtype=np.int32)\n",
    "    next_idxs_counts = np.zeros(max(chars)+1, dtype=np.int32)\n",
    "\n",
    "    for char in chars:\n",
    "        next_idxs_ = np.where(idxs[:-1] == char)[0]\n",
    "        n = len(next_idxs_)\n",
    "\n",
    "        next_idxs[char][:n] = next_idxs_ + 1\n",
    "        next_idxs_counts[char] = n\n",
    "\n",
    "    shuffled_sequences = np.zeros((n_shuffles, *sequence.shape), dtype=np.float32)\n",
    "    counters = np.zeros((n_shuffles, len(chars)), dtype=np.int32)\n",
    "\n",
    "    _fast_shuffle(n_shuffles, chars, idxs, next_idxs, next_idxs_counts, \n",
    "        counters, shuffled_sequences)\n",
    "\n",
    "    shuffled_sequences = torch.from_numpy(shuffled_sequences)\n",
    "    return shuffled_sequences\n",
    "\n",
    "\n",
    "class ProfileModelWrapper(torch.nn.Module):\n",
    "    # this wrapper assumes:\n",
    "    # 1) the model's profile head outputs pre-softmax logits\n",
    "    # 2) the profile output has the last axis as the profile-length dimension\n",
    "    # 3) the softmax should be applied over both strands at the same time\n",
    "    #      (a ala Jacob's bpnetlite implementation of BPNet)\n",
    "    # 4) the profile head is the first of two model outputs\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(ProfileModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        logits, _ = self.model(X)\n",
    "        logits = logits.reshape(logits.shape[0], -1)\n",
    "        mean_norm_logits = logits - torch.mean(logits, axis = -1, keepdims = True)\n",
    "        softmax_probs = torch.nn.Softmax(dim=-1)(mean_norm_logits.detach())\n",
    "        return (mean_norm_logits * softmax_probs).sum(axis=-1)\n",
    "    \n",
    "    \n",
    "class CountsModelWrapper(torch.nn.Module):\n",
    "    # this wrapper assumes the counts head is the second of two model outputs\n",
    "    \n",
    "    def __init__(self, model):\n",
    "        super(CountsModelWrapper, self).__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, X):\n",
    "        _, logcounts = self.model(X)\n",
    "        return logcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3bd93e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import DeepLiftShap\n",
    "\n",
    "prof_shap_explainers = [DeepLiftShap(ProfileModelWrapper(model.cuda())) for model in models]\n",
    "counts_shap_explainers = [DeepLiftShap(CountsModelWrapper(model.cuda())) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a97b639",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 228/228 [112:57:39<00:00, 1783.59s/it]\n"
     ]
    }
   ],
   "source": [
    "def deepshap_once(seq):\n",
    "    assert len(seq.shape) == 3\n",
    "\n",
    "    ref_seqs = dinuc_shuffle(seq[0], 20).float().cuda()\n",
    "    \n",
    "    prof_attrs = []\n",
    "    count_attrs = []\n",
    "    prof_attrs_rc = []\n",
    "    count_attrs_rc = []\n",
    "    \n",
    "    for prof_explainer, counts_explainer in zip(prof_shap_explainers, counts_shap_explainers):\n",
    "        prof_attrs.append(prof_explainer.attribute(seq.cuda(), ref_seqs).cpu().detach().numpy())\n",
    "        count_attrs.append(counts_explainer.attribute(seq.cuda(), ref_seqs).cpu().detach().numpy())\n",
    "        \n",
    "        prof_attrs_rc.append(prof_explainer.attribute(torch.flip(seq, [1,2]).cuda(),\n",
    "                                                      torch.flip(ref_seqs, [1,2])).cpu().detach().numpy())\n",
    "        count_attrs_rc.append(counts_explainer.attribute(torch.flip(seq, [1,2]).cuda(),\n",
    "                                                      torch.flip(ref_seqs, [1,2])).cpu().detach().numpy())\n",
    "    \n",
    "    prof_attrs = np.mean(np.array(prof_attrs), axis=0)\n",
    "    count_attrs = np.mean(np.array(count_attrs), axis=0)\n",
    "    \n",
    "    prof_attrs_rc = np.mean(np.array(prof_attrs_rc), axis=0)\n",
    "    count_attrs_rc = np.mean(np.array(count_attrs_rc), axis=0)\n",
    "    \n",
    "    prof_attrs = np.mean(np.array([prof_attrs, prof_attrs_rc[..., ::-1, ::-1]]), axis=0)\n",
    "    count_attrs = np.mean(np.array([count_attrs, count_attrs_rc[..., ::-1, ::-1]]), axis=0)\n",
    "    \n",
    "    prof_attrs = prof_attrs * seq.numpy()\n",
    "    count_attrs = count_attrs * seq.numpy()\n",
    "    \n",
    "    return prof_attrs.squeeze(), count_attrs.squeeze()\n",
    "\n",
    "\n",
    "def deepshap_one_seq(onehot_seq, skip = 100):\n",
    "    onehot_seq = torch.Tensor(onehot_seq).float()\n",
    "    assert len(onehot_seq.shape) == 2 and onehot_seq.shape[0] == 4, onehot_seq.shape\n",
    "    num_seq_tiles = int(np.ceil((onehot_seq.shape[1] - in_window) / skip + 1))\n",
    "    \n",
    "    scores_all_prof = np.empty((num_seq_tiles, 4, onehot_seq.shape[1]))\n",
    "    scores_all_prof[:] = np.nan\n",
    "    \n",
    "    scores_all_counts = np.empty((num_seq_tiles, 4, onehot_seq.shape[1]))\n",
    "    scores_all_counts[:] = np.nan\n",
    "\n",
    "    tiles_to_do = list(skip * np.arange(0, num_seq_tiles - 1))\n",
    "    # if not a nice even number of tiles to do vs. skips, tack on last window\n",
    "    if tiles_to_do[-1] != onehot_seq.shape[1] - in_window:\n",
    "        tiles_to_do.append(onehot_seq.shape[1] - in_window)\n",
    "    \n",
    "    assert len(tiles_to_do) == num_seq_tiles, (len(tiles_to_do), num_seq_tiles)\n",
    "        \n",
    "    for tile_i, tile_i_skip in enumerate(tiles_to_do):\n",
    "        assert tile_i_skip + in_window <= onehot_seq.shape[1], (tile_i_skip + in_window, onehot_seq.shape[1])\n",
    "        seq_tile = onehot_seq[:, tile_i_skip : tile_i_skip + in_window]\n",
    "\n",
    "        prof_attrs, count_attrs = deepshap_once(seq_tile[None, ...])\n",
    "\n",
    "        assert scores_all_prof[tile_i, :, tile_i_skip : prof_attrs.shape[-1] + tile_i_skip].shape == prof_attrs.shape, (scores_all_prof[tile_i, tile_i_skip : prof_attrs.shape[-1] + tile_i_skip].shape, prof_attrs.shape)\n",
    "        \n",
    "        scores_all_prof[tile_i, :, tile_i_skip : prof_attrs.shape[-1] + tile_i_skip] = prof_attrs\n",
    "        scores_all_counts[tile_i, :, tile_i_skip : count_attrs.shape[-1] + tile_i_skip] = count_attrs\n",
    "    \n",
    "    scores_final_prof = np.nanmean(scores_all_prof, axis=0)\n",
    "    scores_final_counts = np.nanmean(scores_all_counts, axis=0)\n",
    "    return scores_final_prof, scores_final_counts\n",
    "\n",
    "\n",
    "def deepshap_all_seqs(onehot_seqs):\n",
    "    all_scores_prof = []\n",
    "    all_scores_counts = []\n",
    "    for seq in tqdm(onehot_seqs):\n",
    "        scores_prof, scores_counts = deepshap_one_seq(seq)\n",
    "        all_scores_prof.append(scores_prof)\n",
    "        all_scores_counts.append(scores_counts)\n",
    "    return all_scores_prof, all_scores_counts\n",
    "\n",
    "\n",
    "prof_scores, counts_scores = deepshap_all_seqs(onehot_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb99282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model predictions as a dump of lots of little numpy files\n",
    "# (not ideal)\n",
    "\n",
    "tmp_save_dir = \"attrs_npys/\"\n",
    "\n",
    "os.makedirs(tmp_save_dir, exist_ok=True)\n",
    "\n",
    "for attr_i, attrs in enumerate(prof_scores):\n",
    "    np.save(tmp_save_dir + \"prof_\" + str(attr_i) + \".npy\", attrs)\n",
    "    \n",
    "for attr_i, attrs in enumerate(counts_scores):\n",
    "    np.save(tmp_save_dir + \"counts_\" + str(attr_i) + \".npy\", attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "35c87fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing attributions to bigwig.\n",
      "Peaks: TSS_windows.merge.bed\n",
      "Save path: tracks_v2/TSS_windows.scores.prof.bigWig\n",
      "Chrom sizes file: /mnt/lab_data2/kcochran/procapnet/genomes/hg38.withrDNA.chrom.sizes\n"
     ]
    }
   ],
   "source": [
    "# save scores to bigwigs too\n",
    "\n",
    "def load_coords_ragged_for_scores(peaks_file):\n",
    "    lines = []\n",
    "    if peaks_file.endswith(\".gz\"):\n",
    "        with gzip.open(peaks_file) as f:\n",
    "            lines = [line.decode().split()[:3] for line in f]\n",
    "    else:\n",
    "        with open(peaks_file) as f:\n",
    "            lines = [line.split()[:3] for line in f]\n",
    "            \n",
    "    coords = []\n",
    "    for line in lines:\n",
    "        chrom, start, end = line[0], int(line[1]), int(line[2])\n",
    "        coord = (chrom, start - in_window // 2, end + in_window // 2)\n",
    "        if coord[1] < 0:\n",
    "            coord = (chrom, 0, end + in_window // 2)\n",
    "        coords.append(coord)\n",
    "\n",
    "    return coords\n",
    "\n",
    "def write_scores_to_bigwigs(scores,\n",
    "                            peaks_file,\n",
    "                            save_filepath,\n",
    "                            chrom_sizes_filepath):\n",
    "    \n",
    "    # need to flatten scores after one-hot\n",
    "    assert np.sum(np.sum(scores[0] == 0, axis=0) >= 3) == scores[0].shape[-1], np.sum(np.sum(scores[0] == 0, axis=0) >= 3)\n",
    "    scores = [scores_one_ex.sum(axis=0) for scores_one_ex in scores]\n",
    "    \n",
    "    coords = load_coords_ragged_for_scores(peaks_file)\n",
    "    assert len(coords) == len(scores)\n",
    "    \n",
    "    if not (save_filepath.endswith(\".bigWig\") or save_filepath.endswith(\".bw\")):\n",
    "        bw_filename = save_filepath + \".bigWig\"\n",
    "    else:\n",
    "        bw_filename = save_filepath\n",
    "          \n",
    "    print(\"Writing attributions to bigwig.\")\n",
    "    print(\"Peaks: \" + peaks_file)\n",
    "    print(\"Save path: \" + bw_filename)\n",
    "    print(\"Chrom sizes file: \" + chrom_sizes_filepath)\n",
    "\n",
    "    # bigwigs need to be written in order -- so we have to go chromosome by chromosome,\n",
    "    # and the chromosomes need to be numerically sorted (i.e. chr9 then chr10)\n",
    "    chrom_names = load_chrom_names(chrom_sizes_filepath)\n",
    "    chrom_order = {chrom : i for i, chrom in enumerate(chrom_names)}\n",
    "    chromosomes = sorted(list({coord[0] for coord in coords}),\n",
    "                         key = lambda chrom_str : chrom_order[chrom_str])\n",
    "\n",
    "    bw = pyBigWig.open(bw_filename, 'w')\n",
    "    # bigwigs need headers before they can be written to\n",
    "    # the header is just the info you'd find in a chrom.sizes file\n",
    "    bw.addHeader(load_chrom_sizes(chrom_sizes_filepath))\n",
    "\n",
    "    for chrom in chromosomes:\n",
    "        # convert arrays of scores for each peak into dict of base position : score\n",
    "        # this function will average together scores at the same position from different called peaks\n",
    "        track_values_dict = make_track_values_dict(scores, coords, chrom)\n",
    "        num_entries = len(track_values_dict)\n",
    "\n",
    "        starts = sorted(list(track_values_dict.keys()))\n",
    "        ends = [position + 1 for position in starts]\n",
    "        scores_to_write = [track_values_dict[key] for key in starts]\n",
    "\n",
    "        assert len(scores_to_write) == len(starts) and len(scores_to_write) == len(ends)\n",
    "\n",
    "        bw.addEntries([chrom for _ in range(num_entries)], \n",
    "                       starts, ends = ends, values = scores_to_write)\n",
    "\n",
    "    bw.close()\n",
    "\n",
    "write_scores_to_bigwigs(prof_scores, candidate_promoter_regions_bed,\n",
    "                        \"tracks_v2/TSS_windows.scores.prof.bigWig\", chrom_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3ca67ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing attributions to bigwig.\n",
      "Peaks: TSS_windows.merge.bed\n",
      "Save path: tracks_v2/TSS_windows.scores.counts.bigWig\n",
      "Chrom sizes file: /mnt/lab_data2/kcochran/procapnet/genomes/hg38.withrDNA.chrom.sizes\n"
     ]
    }
   ],
   "source": [
    "write_scores_to_bigwigs(counts_scores, candidate_promoter_regions_bed,\n",
    "                        \"tracks_v2/TSS_windows.scores.counts.bigWig\", chrom_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d25392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:procap_A100] *",
   "language": "python",
   "name": "conda-env-procap_A100-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
